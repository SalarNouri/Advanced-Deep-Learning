{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMZXU7tFL1a3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"http://datasets.d2.mpi-inf.mpg.de/mateusz14visual-turing/nyu_depth_images.tar\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miWSq6RGU_Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"https://datasets.d2.mpi-inf.mpg.de/mateusz14visual-turing/qa.894.raw.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etuNTRLwOQhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"http://nlp.stanford.edu/data/glove.6B.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgKZCW2vPwJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKzRECEoNkyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvf nyu_depth_images.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MINOXoygJnhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import torch.cuda as cuda\n",
        "import torch.utils.data as torchdata\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnUSE6KuP1aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-H25VFrQglZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "glove_path = '/content/glove.6B.300d.txt'\n",
        "\n",
        "#create word dictionary\n",
        "def load_glove(path):\n",
        "  with open(path) as f:\n",
        "    glove = {}\n",
        "    for line in f.readlines():\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      vector = np.array(values[1:], dtype='float32')\n",
        "      glove[word] = vector\n",
        "    return glove\n",
        "\n",
        "\n",
        "glove = load_glove(glove_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGRDdXUhWpIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_emb_layer(weights_matrix, non_trainable= False):\n",
        "  num_embeddings, embedding_dim = weights_matrix.shape\n",
        "  emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "  emb_layer.load_state_dict({'weight': torch.from_numpy(weights_matrix)})\n",
        "  if non_trainable:\n",
        "    emb_layer.weight.requires_grad = False\n",
        "  return emb_layer, num_embeddings, embedding_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLjB-iMLVks2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_vocab = set()\n",
        "all_questions = []\n",
        "all_answers = []\n",
        "with open('qa.894.raw.txt') as f:\n",
        "  lines = f.readlines()\n",
        "  for line in lines:\n",
        "    vocab = list(line.split())\n",
        "    vocab = [x.replace(',','') for x in vocab]\n",
        "    if any('?' in s for s in vocab):\n",
        "      temp = copy.deepcopy(vocab)\n",
        "      all_questions.append(temp)\n",
        "    else:\n",
        "      temp = copy.deepcopy(vocab)\n",
        "      all_answers.append(temp)\n",
        "    for i in range(len(vocab)):\n",
        "      if 'image' in vocab[i]:\n",
        "        vocab[i] = 'image'\n",
        "    my_vocab.update(vocab)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BggnlHtJchTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_len = len(my_vocab)\n",
        "weights_matrix = np.zeros((matrix_len, 300))\n",
        "words_found = 0\n",
        "final_vocab = dict()\n",
        "for i, word in enumerate(my_vocab):\n",
        "  try:\n",
        "    if '_' in word:\n",
        "      temp = copy.deepcopy(word)\n",
        "      temp = temp.split('_')\n",
        "      try:\n",
        "        s1 = glove[temp[0]]\n",
        "      except KeyError:\n",
        "        s1 = np.random.normal(scale = 0.6, size=(300, ))\n",
        "      try:\n",
        "        s2 = glove[temp[1]]\n",
        "      except KeyError:\n",
        "        s2 = np.random.normal(scale = 0.6, size=(300, ))\n",
        "      weights_matrix[i] = (s1 + s2) / 2\n",
        "      final_vocab[word] = i\n",
        "      continue\n",
        "    weights_matrix[i] = glove[word]\n",
        "    words_found += 1\n",
        "  except KeyError:\n",
        "    weights_matrix[i] = np.random.normal(scale = 0.6, size=(300, ))\n",
        "  final_vocab[word] = i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFrDTFRfWn5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class my_dataset(Dataset):\n",
        "  def __init__(self,questions, answers, file_path, transform= None):\n",
        "    self.path = file_path\n",
        "    self.transforms = transform\n",
        "    self.questions = questions\n",
        "    self.answers = answers\n",
        "    \n",
        "  def __getitem__(self, item):\n",
        "    current_question = self.questions[item]\n",
        "    current_answer = self.answers[item]\n",
        "    \n",
        "    for i in range(len(current_question)):\n",
        "      if 'image' in current_question[i]:\n",
        "        index = copy.deepcopy(current_question[i])\n",
        "        if index.replace('image','') == '':\n",
        "          index = 'image1'\n",
        "        current_question[i] = 'image'\n",
        "    img_path = self.path + index +'.png'\n",
        "    img = Image.open(img_path)\n",
        "    if self.transforms is not None:\n",
        "      img = self.transforms(img)\n",
        "    \n",
        "    designed_answer = []\n",
        "    designed_answer.append(current_answer[0])\n",
        "    sample = random.sample(current_question, 5)\n",
        "    designed_answer.extend(sample)\n",
        "    sample = random.sample(my_vocab, 26)\n",
        "    designed_answer.extend(sample)\n",
        "    \n",
        "    ans_ind = [final_vocab[x] for x in designed_answer]\n",
        "    ques_ind = [final_vocab[x] for x in current_question]\n",
        "    length = len(ques_ind)\n",
        "    while (len(ques_ind) < 31):\n",
        "      ques_ind.append(0)\n",
        "    \n",
        "    return img, torch.tensor(ques_ind), torch.tensor(ans_ind), torch.tensor(length)\n",
        "    \n",
        "    \n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.questions)\n",
        "batch_size = 32  \n",
        "total_epoch = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N1Xflx1kjkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class network(nn.Module):\n",
        "  def __init__(self, matrix_weights):\n",
        "    super(network, self).__init__()\n",
        "    self.resnet = models.resnet18(pretrained = True)\n",
        "    self.resnet.fc = nn.Sequential()\n",
        "    self.linear_from_resnet_to_lstm = nn.Linear(512, 150)\n",
        "    self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
        "    self.gru = nn.GRU(embedding_dim, 150, 1, batch_first=True)\n",
        "    self.fc1 = nn.Linear(662, 300)\n",
        "    self.fc2 = nn.Linear(300, 300)\n",
        "  \n",
        "  def forward(self, image, question, answers, lengths):\n",
        "    with torch.no_grad():\n",
        "      image_features1 = self.resnet(image)\n",
        "    image_features = self.linear_from_resnet_to_lstm(image_features1)\n",
        "\n",
        "    image_features = image_features.unsqueeze(0)\n",
        "\n",
        "    embedded = self.embedding(question)\n",
        "    embedded = torch.nn.utils.rnn.pack_padded_sequence(embedded, batch_first=True, lengths = lengths, enforce_sorted =False)\n",
        "\n",
        "    lstm_output = self.gru(embedded, image_features)\n",
        "\n",
        "    concated = torch.cat((lstm_output[1].squeeze(0), image_features1), 1)\n",
        "\n",
        "  \n",
        "    output = self.fc1(concated)\n",
        "\n",
        "    output = F.relu(output)\n",
        "    output = self.fc2(output)\n",
        "\n",
        "\n",
        "    answer_vec = self.embedding(answers)\n",
        "    \n",
        "\n",
        "    final_output = torch.einsum('bwf,bf->bw', answer_vec, output)\n",
        "    \n",
        "    return final_output\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzM-xhR2yNPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_path = '/content/nyu_depth_images/'\n",
        "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "test_length = 2500\n",
        "\n",
        "my_data = my_dataset(all_questions, all_answers, images_path, trans)\n",
        "data_range = range(len(my_data))\n",
        "test_index = random.sample(range(len(my_data)),test_length)\n",
        "train_index = [x for x in data_range if x not in test_index]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_index)\n",
        "test_sampler = SubsetRandomSampler(test_index)\n",
        "\n",
        "\n",
        "\n",
        "train_loader = torchdata.DataLoader(my_data, batch_size = batch_size, shuffle=False, sampler = train_sampler)\n",
        "print(len(train_loader))\n",
        "test_loader = torchdata.DataLoader(my_data, batch_size = batch_size, shuffle = False, sampler = test_sampler)\n",
        "print(len(test_loader))\n",
        "\n",
        "my_net = network(weights_matrix)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(my_net.parameters(), lr=0.01,weight_decay = 0.005)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "my_net.to(device)\n",
        "optimizer.zero_grad()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VevBE79ahKpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_loss = list()\n",
        "test_loss = list()\n",
        "for epoch in range(total_epoch):\n",
        "  this_epoch_loss = list()\n",
        "  this_epoch_test_loss= list()\n",
        "  optimizer.zero_grad()\n",
        "  my_net.train()\n",
        "  for i, (image, question, answer, length) in enumerate(train_loader):\n",
        "    image = image.to(device)\n",
        "    question = question.to(device)\n",
        "    answer = answer.to(device)\n",
        "    image = Variable(image)\n",
        "    question = Variable(question)\n",
        "    answer = Variable(answer)\n",
        "    optimizer.zero_grad()\n",
        "    output = my_net(image, question, answer, length)\n",
        "    label = torch.zeros([len(image)], dtype= torch.long)\n",
        "    loss = criterion(output, label.to(device))\n",
        "    loss.backward()\n",
        "    this_epoch_loss.append(loss.item())\n",
        "    print('in epoch {} and index {} loss is {}'.format(epoch, i , this_epoch_loss[-1]))\n",
        "  print('in epoch {} average loss was {}'.format(epoch, np.mean(this_epoch_loss)))\n",
        "  all_loss.append(np.mean(this_epoch_loss))\n",
        "  \n",
        "  my_net.eval()\n",
        "  for i, (image, question, answer, length) in enumerate(test_loader):\n",
        "    image = image.to(device)\n",
        "    question = question.to(device)\n",
        "    answer = answer.to(device)\n",
        "    image = Variable(image)\n",
        "    question = Variable(question)\n",
        "    answer = Variable(answer)\n",
        "    output = my_net(image, question, answer, length)\n",
        "    label = torch.zeros([len(image)], dtype= torch.long)\n",
        "    loss = criterion(output, label.to(device))\n",
        "    this_epoch_test_loss.append(loss.item())\n",
        "    print('in test epoch {} and index {} loss is {}'.format(epoch, i, this_epoch_test_loss[-1]))\n",
        "  print('in test epoch {} average loss was {}'.format(epoch, np.mean(this_epoch_test_loss)))\n",
        "  test_loss.append(np.mean(this_epoch_test_loss))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z47yCn3hgW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot(all_loss,'r', label = 'train_loss')\n",
        "plt.plot(test_loss,'b', label = 'test_loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('average loss in epoch')\n",
        "plt.xlabel('# of epoch')\n",
        "plt.ylabel('average Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}