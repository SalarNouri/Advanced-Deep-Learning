{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "EfficientNet.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vzxqb7MW99e"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k00A3abjg3f"
      },
      "source": [
        "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet\\\n",
        "       /noisystudent/noisy_student_efficientnet-b0.tar.gz\n",
        "!tar -xf noisy_student_efficientnet-b0.tar.gz\n",
        "\n",
        "\n",
        "!python efficientnet_weight_update_util.py --model b1 --notop --ckpt \\\n",
        "        efficientnet-b1/model.ckpt --o efficientnetb1_notop.h5\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTzXjXmEVE3L"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from keras import layers, models, Model, optimizers, losses, metrics, regularizers, callbacks, initializers\n",
        "\n",
        "IMG_SIZE: int = 224\n",
        "BATCH_SIZE: int = 64\n",
        "EPOCHES: int = 4 \n",
        "NUM_CLASSES: int = 196\n",
        "top_dropout_rate: np.float = 0.2 \n",
        "# # @param {type: \"slider\", min:1, max:100}\n",
        "\n",
        "metrics = [\n",
        "    metrics.FalseNegatives(name=\"fn\"),\n",
        "    metrics.FalsePositives(name=\"fp\"),\n",
        "    metrics.TrueNegatives(name=\"tn\"),\n",
        "    metrics.TruePositives(name=\"tp\"),\n",
        "    metrics.Precision(name=\"precision\"),\n",
        "    metrics.Recall(name=\"recall\"),\n",
        "    metrics.Accuracy(name='acc')\n",
        "    metrics.AUC(name='auc'),\n",
        "    metrics.AUC(name='prc', curve='PR')\n",
        "]\n",
        "\n",
        "\n",
        "def input_preprocess(image, label):\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"accuracy\"])\n",
        "    plt.plot(hist.history[\"val_accuracy\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_metrics(history):\n",
        "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
        "  colors = ['b', 'g', 'r', 'y']\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1)\n",
        "    plt.plot(history.epoch, history.history[metric], color='b', label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\n",
        "             color='r', linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "def build_model(NUM_CLASSES):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    # x = img_augmentation(inputs)\n",
        "    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\") # weights=\"efficientnetb1_notop.h5\"\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=1e-2),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=metrics\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=metrics)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q41uUSU7Xvvp"
      },
      "source": [
        "# model = EfficientNetB0(weights='imagenet')\n",
        "model = EfficientNetB0(include_top=False, weights='imagenet', drop_connect_rate=0.4)\n",
        "\n",
        "# prepare dataset like the ds_train!!!!!!!!!!\n",
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "\n",
        "ds_train = ds_train.map(input_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_train = ds_train.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(input_preprocess)\n",
        "ds_test = ds_test.batch(batch_size=batch_size, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D4OZxYva67h"
      },
      "source": [
        "with strategy.scope():\n",
        "    model = build_model(num_classes=NUM_CLASSES)\n",
        "    \n",
        "model.summary()\n",
        "\n",
        "model_history = model.fit(ds_train,\n",
        "                          epochs=EPOCHES,\n",
        "                          validation_split=0.2,\n",
        "                          verbose=2,\n",
        "                          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}